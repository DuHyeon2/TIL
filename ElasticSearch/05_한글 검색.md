![Image](https://github.com/user-attachments/assets/c4318983-db7b-4768-a789-7c33a3fbf220)

# 한글 검색

## 1. 한글 검색의 어려움
- 한글은 띄어쓰기가 없고, 조사와 어미가 다양하게 붙는다.
- 예를 들어 "사과"와 "사과를"은 같은 단어지만 의미없는 조사 때문에 다른 단어로 인식된다.
- 따라서 단순한 문자열 검색으로는 정확한 결과를 얻기 어렵다.
## 2. 한글 검색을 위한 애널라이저
- 한글 검색을 위해서는 한글 전용 애널라이저가 필요하다.
- 대표적으로 `nori` 애널라이저가 있다.
## 3. nori 애널라이저 사용법
- 필터 적용
    ```json
    PUT /boards
    {
        "settings": {
            "analysis": {
                "analyzer": {
                    "boards_content_analyzer": {
                        "char_filter": [],
                        "tokenizer": "nori_tokenizer",
                        "filter": ["nori_part_of_speech", "nori_readingform", "lowercase"]
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "content": {
                    "type": "text",
                    "analyzer": "boards_content_analyzer"
                }
            }
        }
    }
    ```

- 분석 예제
    ```json
    GET /boards/_analyze
    {
        "text": "백화점에서 쇼핑을 하다가 친구들을 만났다.",
        "analyzer": "boards_content_analyzer"
    }
    ```

- 결과
    ```json
    {
        "tokens": [
            { "token": "백화"},
            { "token": "점"},
            { "token": "쇼핑"},
            { "token": "하"},
            { "token": "친구"},
            { "token": "만나"}
        ]
    }
    ```
- `char_filter`: 문자 필터링을 위한 설정
- `tokenizer`: `nori_tokenizer`를 사용하여 한글을 토큰화
- `filter`: `nori_part_of_speech`, `nori_readingform`, `lowercase` 필터를 적용
- `nori_part_of_speech`: 의미없는 조사를 제거하고 형태소 분석
- `nori_readingform`: 한자를 한글로 변환
- `lowercase`: 소문자로 변환하여 검색의 일관성 유지
- `GET /boards/_analyze`: 애널라이저를 사용하여 "사과를 먹었다"라는 문장을 분석
- 결과는 형태소 분석을 통해 "사과", "먹다"와 같은 토큰으로 분리되어 반환된다.
